{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf9a821-251f-4f1d-b5e6-5f173b9e9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from category_encoders import OrdinalEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca15dd1-30af-4513-ae71-96c8ee6b2e4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87bcdacc-0e24-43e4-81e6-712cf90428e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clusters(df, col, y, n_cluster, merge=False):\n",
    "    '''\n",
    "        function to boil down a colum to n_cluster\n",
    "        \n",
    "        recive:\n",
    "        \n",
    "            df: a data frame \n",
    "            col: col to make cluster\n",
    "            y: the response variable\n",
    "            n_cluster: stamitation of number of cluster\n",
    "            \n",
    "        return:  \n",
    "            a data frame with 'col' droped, and 'col' + '_cluster' column\n",
    "            is added to the data frame\n",
    "\n",
    "        \n",
    "    '''\n",
    "    col_clusters = KMeans(n_clusters=n_cluster, random_state=777)\n",
    "\n",
    "    # 'Neighborhood' and 'MSSubClass' stats\n",
    "    col_stats = df.groupby(col)[y].describe()\n",
    "\n",
    "    # Getting clusters\n",
    "    col_clusters.fit(col_stats)\n",
    "\n",
    "    # preparing DF with cluster lables to merge\n",
    "    new_name = col + '_Cluster'\n",
    "    col_cluster_df = pd.DataFrame( { col: col_stats.index.to_list(),\n",
    "                                     new_name: col_clusters.labels_.tolist()} )\n",
    "    \n",
    "    if merge:\n",
    "        # merging the clusters with the data frame\n",
    "        df = df.merge(col_cluster_df, how='left', on=col)\n",
    "\n",
    "        df[new_name] = df[new_name].astype(str)\n",
    "        \n",
    "        result = df.drop(columns=col)\n",
    "        \n",
    "    else:\n",
    "        result = col_cluster_df\n",
    "    \n",
    "    return result.copy()\n",
    "\n",
    "\n",
    "# Low frequency categories to 'Other'\n",
    "def lower_than(df, col, percentage):\n",
    "    ''' function that will merge low frequency classes into \n",
    "        a single class 'Others'\n",
    "\n",
    "        parameters:\n",
    "            df: a DataFrame\n",
    "            col: column's name to work on\n",
    "            percentage(%): the threshold like 0.1, 0.2\n",
    "\n",
    "        returns:\n",
    "            df: the data frame with col's classes that are lowers\n",
    "                than 'threshold' been repleced with 'Other' category\n",
    "    '''\n",
    "\n",
    "    # calculating the column frequency\n",
    "    col_freq = df[col].value_counts(normalize=True)\n",
    "\n",
    "    # the getting the column threshold \n",
    "    threshold = col_freq.quantile(q= percentage)\n",
    "\n",
    "    # knowing the classes that are below the threshold\n",
    "    less_freq_classes = col_freq[ col_freq <= threshold ]\n",
    "\n",
    "    others = less_freq_classes.index.to_list()\n",
    "\n",
    "    print(others)\n",
    "\n",
    "    df[col] = df[col].replace(others, 'Others')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef4fc7-4204-4d8c-831b-e2e51c0ff471",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52feccc9-d49a-424c-91d7-7a1256354911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(verbose=False):\n",
    "    \n",
    "    d_tr = pd.read_csv('/Users/antirrabia/Documents/01-GitHub/DataMining-_-/CSV/HousePrices/train.csv', index_col='Id')\n",
    "    d_te = pd.read_csv('/Users/antirrabia/Documents/01-GitHub/DataMining-_-/CSV/HousePrices/test.csv', index_col='Id')\n",
    "    \n",
    "    # Utilities has just 2 categories, and one of them\n",
    "    # just appears once so we delete the whole column.\n",
    "    d_tr = d_tr.drop(columns='Utilities')\n",
    "    d_te = d_te.drop(columns='Utilities')\n",
    "    \n",
    "    # Marking Training Set\n",
    "    d_tr['Training'] = True\n",
    "    d_te['Training'] = False  \n",
    "    \n",
    "    if(verbose):\n",
    "        print('d_tr shape:', d_tr.shape)\n",
    "        print('d_te shape:', d_te.shape)\n",
    "        \n",
    "    return (d_tr.copy(), d_te.copy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94dca3a-3bcd-4417-ba6a-079ff16ee895",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Analazy 'Y'('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a17f4ce-7db5-4633-8cf2-77153160f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_y(df, verbose=False):\n",
    "    \n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Plotting\n",
    "    if(verbose):\n",
    "        fg, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(11,7))\n",
    "        # chequing the distribution of 'y' = 'SalePrice'\n",
    "        \n",
    "        sns.histplot( df['SalePrice'], bins=50, ax= ax1);\n",
    "        ax1.title.set_text('Skewed SalePrice')\n",
    "    \n",
    "        sns.scatterplot(x=df['GrLivArea'], y=df['SalePrice'], ax=ax3);\n",
    "        ax3.title.set_text('Outliers')\n",
    "    \n",
    "    outliers = df[ df['GrLivArea'] >= 4500].index\n",
    "    \n",
    "    # deleting the outliers in 'GrLivArea'\n",
    "    df.drop(outliers, inplace=True)\n",
    "    \n",
    "    # Plotting\n",
    "    if(verbose):\n",
    "        # cheking again\n",
    "        sns.scatterplot(x=df['GrLivArea'], y=df['SalePrice'], ax=ax4);\n",
    "        ax4.title.set_text('NO Outliers')\n",
    "    \n",
    "    # pipeline to scale and do a powerTransforme on y('SalePrice')\n",
    "    fix_y = Pipeline([('scaler', RobustScaler()), ('power', PowerTransformer(method='yeo-johnson'))])\n",
    "    \n",
    "    y = fix_y.fit_transform( df['SalePrice'].values.reshape(-1, 1) )\n",
    "    \n",
    "    # Plotting\n",
    "    if(verbose):\n",
    "        # checking the distribution of 'y' again\n",
    "        sns.histplot(y, bins=50, ax=ax2);\n",
    "        ax2.title.set_text('yeo-johnson transformed \\'y\\'')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    df['SalePrice'] = y.copy()\n",
    "    \n",
    "    return df.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4e36f-2405-4d18-9056-5c998eb3e7ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Combining training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165e0f7d-a6db-49df-ae96-26052ea2a0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tr_te(df_tr, df_te, verbose=False):\n",
    "    \n",
    "    all_d = pd.concat([d_tr.copy(), d_te.copy()])\n",
    "    \n",
    "    if(verbose):\n",
    "        print('New data shape: ', all_d.shape)\n",
    "        \n",
    "    return all_d.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ade99-7886-4637-89f1-9c7b0dff611d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Imputting 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f383d9-7b69-4ad6-a79a-605c0c65c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_nan(all_data):\n",
    "    \n",
    "    # 34 columns with nan\n",
    "    def fillWithNone(df):\n",
    "        ''' nan in 'PoolQC' means 'no pool' \n",
    "            nan in 'MiscFeature' means 'no misc feature'\n",
    "            nan in 'Alley' means 'no alley acces'\n",
    "            nan in 'Fence' means 'no fence'\n",
    "            nan in 'FireplaceQu' means 'no Fireplace'\n",
    "            nan in 'GarageType', 'GarageFinish', 'GarageQual',\n",
    "                'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1'\n",
    "                'BsmtFinType1', 'MasVnrType', 'MSSubClass'\n",
    "                'GarageCond' replaced with 'None' too\n",
    "\n",
    "            recive a df\n",
    "        '''\n",
    "\n",
    "        df = df.copy()\n",
    "\n",
    "        columns = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', \n",
    "                   'FireplaceQu', 'GarageType', 'GarageFinish', \n",
    "                   'GarageQual', 'GarageCond', 'BsmtQual',\n",
    "                   'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
    "                   'BsmtFinType2', 'MasVnrType'\n",
    "                  ]\n",
    "\n",
    "        for col in columns:\n",
    "            df[col] = df[col].fillna('None')\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fillWithZero(df):\n",
    "        ''' nan \n",
    "\n",
    "        '''\n",
    "\n",
    "        df = df.copy()\n",
    "\n",
    "        columns = ['GarageYrBlt', 'GarageArea', 'GarageCars',\n",
    "                   'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                   'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath',\n",
    "                   'MasVnrArea'\n",
    "                  ]\n",
    "\n",
    "        for col in columns:\n",
    "            df[col] = df[col].fillna(0)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fillWithMode(df):\n",
    "        ''' fill missing values with mode, median\n",
    "        '''\n",
    "        df = df.copy()\n",
    "\n",
    "        columns = ['Electrical', 'KitchenQual', 'Exterior1st',\n",
    "                   'Exterior2nd', 'SaleType'\n",
    "                  ]\n",
    "\n",
    "        for col in columns:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "        # filling with median of each 'Neighborhood'\n",
    "        df['LotFrontage'] = (\n",
    "                         df.groupby('Neighborhood')['LotFrontage']\n",
    "                         .transform(lambda x: x.fillna(x.median()))\n",
    "                        )  \n",
    "\n",
    "        # nan means Typical\n",
    "        df['Functional'] = df['Functional'].fillna('Typ')\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def mszoning(df):\n",
    "        ''' recives a DF this imputation takes place on test data only'''\n",
    "\n",
    "        df = df.copy()\n",
    "\n",
    "        idotrr = ( (df['Neighborhood'] == 'IDOTRR') & (df['MSZoning'].isna()) )\n",
    "        mitchel = ( (df['Neighborhood'] == 'Mitchel') & (df['MSZoning'].isna()) )\n",
    "\n",
    "        df.loc[ idotrr , 'MSZoning'] = 'RM'\n",
    "        df.loc[ mitchel, 'MSZoning'] = 'RL'\n",
    "\n",
    "    #     # to test this function out of here\n",
    "    #     temp = mszoning(d_te)\n",
    "    #     # lable index acces at [1916, 2217, 2251, 2905\n",
    "    #     temp.loc[[1916, 2217, 2251, 2905], 'MSZoning']\n",
    "\n",
    "        return df\n",
    "\n",
    "    none_func = FunctionTransformer(fillWithNone, validate=False) \n",
    "    zero_func = FunctionTransformer(fillWithZero, validate=False) \n",
    "    mode_func = FunctionTransformer(fillWithMode, validate=False)\n",
    "    mszo_func = FunctionTransformer(mszoning, validate=False)\n",
    "    \n",
    "    \n",
    "    imputer = Pipeline([\n",
    "                    ('withNone', none_func), \n",
    "                    ('withZero', zero_func), \n",
    "                    ('withMode', mode_func), \n",
    "                    ('mszoni', mszo_func)\n",
    "                   ])\n",
    "    \n",
    "    result = imputer.fit_transform(all_data)\n",
    "    \n",
    "    return result.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332fe660-3a2d-4178-ad09-ee1ceed3dbbb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Reduce Categories(Collapsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b2e37e1-4772-4ec5-94f3-3cd2beaac333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_categories(all_data):\n",
    "    \n",
    "#     # Low frequency categories to 'Other'\n",
    "#     def lower_than(df, col, percentage):\n",
    "#         ''' function that will merge low frequency classes into \n",
    "#             a single class 'Others'\n",
    "\n",
    "#             parameters:\n",
    "#                 df: a DataFrame\n",
    "#                 col: column's name to work on\n",
    "#                 percentage(%): the threshold like 0.1, 0.2\n",
    "\n",
    "#             returns:\n",
    "#                 df: the data frame with col's classes that are lowers\n",
    "#                     than 'threshold' been repleced with 'Other' category\n",
    "#         '''\n",
    "\n",
    "#         # calculating the column frequency\n",
    "#         col_freq = df[col].value_counts(normalize=True)\n",
    "\n",
    "#         # the getting the column threshold \n",
    "#         threshold = col_freq.quantile(q= percentage)\n",
    "\n",
    "#         # knowing the classes that are below the threshold\n",
    "#         less_freq_classes = col_freq[ col_freq <= threshold ]\n",
    "\n",
    "#         others = less_freq_classes.index.to_list()\n",
    "\n",
    "#         print(others)\n",
    "\n",
    "#         df[col] = df[col].replace(others, 'Others')\n",
    "\n",
    "#         return df\n",
    "\n",
    "\n",
    "\n",
    "    con1_others = ['RRAn', 'PosN', 'RRAe', 'PosA', 'RRNn', 'RRNe']\n",
    "    roofS_others = ['Gambrel', 'Flat', 'Mansard', 'Shed']\n",
    "    foun_others = ['Slab', 'Stone', 'Wood']\n",
    "    gara_others = ['None', 'Basment', '2Types', 'CarPort']\n",
    "    saleT_others = ['ConLD', 'CWD', 'ConLI', 'ConLw', 'Oth', 'Con']\n",
    "    saleC_others = ['Family', 'Alloca', 'AdjLand']\n",
    "    exte1_others = ['BrkComm', 'AsphShn', 'Stone', 'CBlock', 'ImStucc']\n",
    "    exte2_others = ['BrkComm', 'AsphShn', 'Stone', 'CBlock', 'ImStucc', 'Other']\n",
    "    lotC_others = ['FR2', 'FR3']\n",
    "\n",
    "    all_data['Condition1'] = all_data['Condition1'].map(lambda x: 'Others' if x in con1_others else x)\n",
    "    all_data['RoofStyle'] = all_data['RoofStyle'].map(lambda x: 'Others' if x in roofS_others else x)\n",
    "    all_data['Foundation'] = all_data['Foundation'].map(lambda x: 'Others' if x in foun_others else x)\n",
    "    all_data['GarageType'] = all_data['GarageType'].map(lambda x: 'Others' if x in gara_others else x)\n",
    "    all_data['SaleType'] = all_data['SaleType'].map(lambda x: 'Others' if x in saleT_others else x)\n",
    "    all_data['SaleCondition'] = all_data['SaleCondition'].map(lambda x: 'Others' if x in saleC_others else x)\n",
    "    all_data['Exterior1st'] = all_data['Exterior1st'].map(lambda x: 'Others' if x in exte1_others else x)\n",
    "    all_data['Exterior2nd'] = all_data['Exterior2nd'].map(lambda x: 'Others' if x in exte2_others else x)\n",
    "    all_data['LotConfig'] = all_data['LotConfig'].map(lambda x: 'Others' if x in lotC_others else x)\n",
    "\n",
    "\n",
    "    # Reducing to a BINARY CLASSES(just 2 clases)\n",
    "\n",
    "    landC_others = ['HLS', 'Bnk', 'Low']\n",
    "    cond2_others = ['Feedr', 'Artery', 'PosN', 'PosA', 'RRNn', 'RRAn', 'RRAe']\n",
    "    roofM_others = ['Tar&Grv', 'WdShake', 'WdShngl', 'Metal', 'Membran', 'Roll', 'ClyTile']\n",
    "    heati_others = ['GasW', 'Grav', 'Wall', 'OthW', 'Floor']\n",
    "    elect_others = ['FuseA', 'FuseF', 'FuseP', 'Mix']\n",
    "    miscF_others = ['Shed', 'Gar2', 'Othr', 'TenC']\n",
    "\n",
    "    all_data['LandContour'] = all_data['LandContour'].map(lambda x: 'Others' if x in landC_others else x)\n",
    "    all_data['Condition2'] = all_data['Condition2'].map(lambda x: 'Others' if x in cond2_others else x)\n",
    "    all_data['RoofMatl'] = all_data['RoofMatl'].map(lambda x: 'Others' if x in roofM_others else x)\n",
    "    all_data['Heating'] = all_data['Heating'].map(lambda x: 'Others' if x in heati_others else x)\n",
    "    all_data['Electrical'] = all_data['Electrical'].map(lambda x: 'Others' if x in elect_others else x)\n",
    "\n",
    "    all_data['MiscFeature'] = all_data['MiscFeature'].map(lambda x: 'Others' if x in miscF_others else x)\n",
    "    \n",
    "    \n",
    "    return all_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f29a9b-652d-4150-b0cd-d8208223ca2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb5c6fd-4af0-459c-8cc6-ab0ee2914b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def features_engineering(all_data):\n",
    "    # Before using d_tr set \n",
    "    # get the new d_tr set from all_data\n",
    "    d_tr = all_data[all_data['Training']].copy()\n",
    "\n",
    "    # Creating a new feature 'PeakMonths', 'Unfinished',\n",
    "    # 'Splited', and TotalSF\n",
    "    peak_moS = [5, 6, 7]\n",
    "    unfi_hou = ['1.5Unf', '2.5Unf']\n",
    "    spli_hou = ['SFoyer', 'SLvl']\n",
    "\n",
    "    all_data['PeakMonths'] = all_data['MoSold'].map(lambda x: 'Peak' if x in peak_moS else 'Normal' )\n",
    "    all_data['Finished']   = all_data['HouseStyle'].map(lambda x: 'no' if x in unfi_hou else 'yes') \n",
    "    all_data['Splited']    = all_data['HouseStyle'].map(lambda x: 'yes' if x in spli_hou else 'no')\n",
    "\n",
    "    all_data['TotalSF']    = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "\n",
    "\n",
    "    # we will use the training data because if we uses all_data\n",
    "    # it has 'nan' in 'SalePrice'. test data does not have 'SalePrice'\n",
    "    # 'Neighborhood', 5, 'MSSubClass', 4\n",
    "    nei_cluster = make_clusters(d_tr.copy(), 'Neighborhood', 'SalePrice', 5)\n",
    "    mss_cluster = make_clusters(d_tr.copy(), 'MSSubClass', 'SalePrice', 4)\n",
    "\n",
    "    # merging the clusters with the data frame\n",
    "    # we got a 'nan' cluster becouse 'MSSubClass' in test\n",
    "    # has a '150' class that is just in test\n",
    "    all_data = all_data.merge(nei_cluster, how='left', on='Neighborhood')\n",
    "    all_data.drop(columns='Neighborhood', inplace=True)\n",
    "\n",
    "    all_data = all_data.merge(mss_cluster, how='left', on='MSSubClass')\n",
    "    all_data.drop(columns='MSSubClass', inplace=True)\n",
    "\n",
    "    all_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # updating the ** new feature ** types\n",
    "    all_data = all_data.astype( {'PeakMonths':str, 'Finished':str, 'Splited':str,\n",
    "                           'Neighborhood_Cluster': str, 'MSSubClass_Cluster': str} )\n",
    "    \n",
    "    return all_data.copy()\n",
    "\n",
    "# # updating cat_to_1Hot\n",
    "# cat_to_1Hot.update( {'PeakMonths':str, 'Finished':str, 'Splited':str,\n",
    "#                        'Neighborhood_Cluster': str, 'MSSubClass_Cluster': str} )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2753745-3428-4207-bc5b-661943b375f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Global Variables\n",
    "> ord_cat_mapping  \n",
    "> cat_to_1Hot  \n",
    "> ord_cat_DONE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1bd0b41-503b-4d5d-9c6e-2e4c221f0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ****** All writed by me ****** #####\n",
    "##########################################\n",
    "def get_global_variables():\n",
    "    ord_cat_mapping = [\n",
    "        {\n",
    "            'col': 'FireplaceQu',\n",
    "            'mapping': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "        },\n",
    "        {\n",
    "            'col': 'GarageQual',\n",
    "            'mapping': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "        },\n",
    "        {\n",
    "            'col': 'GarageCond',\n",
    "            'mapping': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "        },\n",
    "        {\n",
    "            'col': 'BsmtFinType1',\n",
    "            'mapping': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "        },\n",
    "        {\n",
    "            'col': 'BsmtFinType2',\n",
    "            'mapping': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "        },\n",
    "        {\n",
    "            'col': 'ExterQual',\n",
    "            'mapping': {'Fa': 0, 'TA': 1, 'Gd': 2, 'Ex': 3}\n",
    "        },\n",
    "        {\n",
    "            'col': 'ExterCond',\n",
    "            'mapping': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\n",
    "        },\n",
    "        {\n",
    "            'col': 'BsmtQual',\n",
    "            'mapping': {'None': 0 , 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\n",
    "        },\n",
    "        {\n",
    "            'col': 'BsmtCond',\n",
    "            'mapping': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4}\n",
    "        },\n",
    "        {\n",
    "            'col': 'PoolQC',\n",
    "            'mapping': {'None': 0, 'Fa': 1, 'Gd': 2, 'Ex': 3}\n",
    "        },\n",
    "        {\n",
    "            'col': 'HeatingQC',\n",
    "            'mapping': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\n",
    "        },\n",
    "        {\n",
    "            'col': 'KitchenQual',\n",
    "            'mapping': {'Fa': 0, 'TA': 1, 'Gd': 2, 'Ex': 3}\n",
    "        },\n",
    "        {\n",
    "            'col': 'BsmtExposure',\n",
    "            'mapping': {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}\n",
    "        },\n",
    "        {\n",
    "            'col': 'Functional',\n",
    "            'mapping': {'Sev': 0, 'Maj2': 1, 'Maj1': 2, 'Mod': 3, 'Min2': 4, 'Min1': 5, 'Typ': 6}\n",
    "        },\n",
    "        {\n",
    "            'col': 'GarageFinish',\n",
    "            'mapping': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "        },\n",
    "        {\n",
    "            'col': 'Fence',\n",
    "            'mapping': {'None': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n",
    "        },\n",
    "        {\n",
    "            'col': 'CentralAir',\n",
    "            'mapping': {'N': 0, 'Y': 1}\n",
    "        },\n",
    "        {\n",
    "            'col': 'PavedDrive',\n",
    "            'mapping': {'N': 0, 'P': 1, 'Y': 2}\n",
    "        },\n",
    "        {\n",
    "            'col': 'Street',\n",
    "            'mapping': {'Grvl': 0, 'Pave': 1}\n",
    "        },\n",
    "        {\n",
    "            'col': 'Alley',\n",
    "            'mapping': {'None': 0, 'Grvl': 1, 'Pave': 2}\n",
    "        },\n",
    "        {\n",
    "            'col': 'LandSlope',\n",
    "            'mapping': {'Gtl': 0, 'Mod': 1, 'Sev': 2}\n",
    "        },\n",
    "        {\n",
    "            'col': 'LotShape',\n",
    "            'mapping': {'Reg': 0, 'IR1': 1, 'IR2': 2, 'IR3': 3}\n",
    "        },\n",
    "        {\n",
    "            'col': 'HouseStyle', \n",
    "            'mapping': {'SLvl': 0, 'SFoyer': 0, '1Story': 1, '1.5Fin': 2, \n",
    "                        '1.5Unf': 2, '2Story': 3, '2.5Unf': 4, '2.5Fin': 4}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # list of categorical columns(23)  \n",
    "    # that we just encoded\n",
    "    ord_cat_DONE = {'FireplaceQu': str, 'GarageQual': str,'GarageCond': str,'BsmtFinType1': str,\n",
    "                     'BsmtFinType2': str,'ExterQual': str,'ExterCond': str,'BsmtQual': str,\n",
    "                     'BsmtCond': str,'PoolQC': str,'HeatingQC': str,'KitchenQual': str,\n",
    "                     'BsmtExposure': str,'Functional': str,'GarageFinish': str,'Fence': str, \n",
    "                     'CentralAir': str, 'PavedDrive': str,'Street': str,'Alley': str,\n",
    "                     'LandSlope': str,'LotShape': str, 'HouseStyle': str}\n",
    "\n",
    "    # to encode using OneHot (15 so far)\n",
    "    cat_to_1Hot = {'Condition1': str, 'RoofStyle': str, 'Foundation': str, 'GarageType': str, 'SaleType': str, \n",
    "                   'SaleCondition': str, 'Exterior1st': str, 'Exterior2nd': str, 'LotConfig': str, 'LandContour': str, \n",
    "                   'Condition2': str, 'RoofMatl': str, 'Heating': str, 'Electrical': str, 'MiscFeature': str }\n",
    "\n",
    "    # updating cat_to_1Hot with new created features\n",
    "    cat_to_1Hot.update( {'PeakMonths':str, 'Finished':str, 'Splited':str,\n",
    "                           'Neighborhood_Cluster': str, 'MSSubClass_Cluster': str} )\n",
    "\n",
    "    # updating the types\n",
    "    # update the list of ordinal with 2 columns name\n",
    "    # that allredy are ordinal and encoded ('OverallQual', 'OverallCond')\n",
    "\n",
    "    ord_cat_DONE.update({'OverallQual': str, 'OverallCond': str})\n",
    "    # new_d = new_d.astype(ord_cat_DONE)\n",
    "\n",
    "    # 5 more columns will concidere as categorical\n",
    "    cat_to_1Hot.update({'MoSold': str, 'YrSold': str, 'BldgType':str, \n",
    "                        'MSZoning': str, 'MasVnrType': str})\n",
    "\n",
    "    # new_d = new_d.astype(cat_to_1Hot)\n",
    "    \n",
    "    # updating the data type\n",
    "    # df = df.astype(cat_to_1Hot)\n",
    "    # df = df.astype(ord_cat_DONE)\n",
    "    \n",
    "    return (ord_cat_mapping, ord_cat_DONE, cat_to_1Hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0837ed-4ff2-4ff0-8757-22bd1ab8858e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Ordinal and OneHot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb0ea81b-798a-4140-b820-f079c439f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_1hot_encode(all_data, ord_mapping, oneHot_col):\n",
    "    \n",
    "    ## OrdinalEncoder\n",
    "    oe = OrdinalEncoder(mapping=ord_mapping).fit(all_data)\n",
    "    \n",
    "    all_data = oe.transform(all_data)\n",
    "    \n",
    "    \n",
    "    ## OneHot encoding\n",
    "    oh = OneHotEncoder(cols=oneHot_col).fit(all_data)\n",
    "    \n",
    "    all_data = oh.transform(all_data.copy())\n",
    "    \n",
    "    \n",
    "    \n",
    "    return all_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baf713e-99a7-4ca7-9461-f8baf513f1fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0ae2292-19fb-42fe-bc1e-9f5853c623f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X, y, verbose=False, sorted_features=False):\n",
    "    \n",
    "    mutual_info = mutual_info_regression(X=X, y=y)\n",
    "    \n",
    "    mu_info_df = pd.DataFrame(list(zip( X.columns, mutual_info )), columns=['Features', 'Mutual_info'])\n",
    "    \n",
    "    feature_to_dop = mu_info_df[ mu_info_df['Mutual_info'] == 0]\n",
    "    feature_to_dop = list( feature_to_dop['Features'] )\n",
    "    \n",
    "    if(verbose):\n",
    "        #Sorting\n",
    "        # mu_info_df.sort_values('Mutual_info', ascending=False, inplace=True)\n",
    "        print('{} Features with Zero(0) mutual info: \\n'.format(len(feature_to_dop)))\n",
    "        feature_to_dop = sorted(feature_to_dop)\n",
    "        print(feature_to_dop)\n",
    "        \n",
    "    if( (verbose == False) and sorted_features):\n",
    "        feature_to_dop = sorted(feature_to_dop)\n",
    "        \n",
    "    \n",
    "    return (feature_to_dop, mu_info_df.sort_values('Mutual_info', ascending=False).copy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffaf039-97dd-424a-9acc-8e29383765df",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fix skewed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f22fb205-9101-4bfc-bc98-fde5ed0cf9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_skew_cols(df, cols, treshold=0.7):\n",
    "    \n",
    "    skewed = all_d[cols].skew()\n",
    "    \n",
    "    skewed = skewed[skewed >= 0.7]\n",
    "    skewed = skewed.index\n",
    "    \n",
    "    print('{} features with skewe >= { }'.format( len(skewed), treshold ) )\n",
    "    \n",
    "    fix_data_skew = Pipeline([('scaler', RobustScaler()), \n",
    "                          ('yeo', PowerTransformer(method='yeo-johnson'))])\n",
    "    \n",
    "    df[skewed] = fix_data_skew.fit_transform(df[skewed].copy())\n",
    "    \n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9749dfe-6caa-4b9f-9ab2-06c9e6555f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1295d7-38b0-47f0-93db-9b8527da853c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d76b9e1c-5469-49f1-a37d-97d33dc29cd0",
   "metadata": {},
   "source": [
    "# Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af68c83-8ecc-46e4-8d5b-1fc378142d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "d_tr, d_te = data(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170f1fd-2d3a-4c47-b7b8-850af2319f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking cara of some outliers\n",
    "# and making more gausian 'y'\n",
    "d_tr = analyze_y(d_tr.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b937b56-d08f-46b3-9506-022753886a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after take care of some outlier\n",
    "# combine the training and the test\n",
    "all_d = combine_tr_te(d_tr.copy(), d_te.copy(), verbose=True)\n",
    "all_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1aea8-67b8-46c2-9d9e-652d48a3e0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing nan\n",
    "all_d = impute_nan(all_d.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c2f0a-1380-44bd-ba48-e68cfbdac267",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_d.columns[all_d.isna().any()].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86001183-b5b7-452d-9622-49c154193ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the number of categories in some columns\n",
    "all_d = reduce_categories(all_d.copy())\n",
    "# all_d['Foundation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a466796c-7055-421b-b38d-e0995b1228ec",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9dd6d-6a96-4dc8-9902-22bc5ef269aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new columns like cluster ...\n",
    "all_d = features_engineering(all_d.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542211c3-9dcf-4e24-8e48-c286c4b409e1",
   "metadata": {},
   "source": [
    "### Categorical and Number Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647b158-d279-4add-9b25-332a7a3f5267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the global variables\n",
    "ord_cat_mapping, ord_cat_DONE, cat_to_1Hot = get_global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1c18f3-988c-48f9-94ef-5bd620ae359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the data type\n",
    "all_d = all_d.astype(cat_to_1Hot)\n",
    "all_d = all_d.astype(ord_cat_DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1c448-e544-4f53-8b6a-bd105ba121e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the number columns\n",
    "numbers_col = all_d.select_dtypes('number')\n",
    "numbers_col = numbers_col.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710eaf2-b38f-4fc9-8083-c706286e948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_col = numbers_col + list(cat_to_1Hot.keys()) + list(ord_cat_DONE.keys())\n",
    "set( all_d.columns.to_list() ) - set( analyzed_col )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbe87d-f5a5-4c34-8209-a9f03eee4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set( analyzed_col ) - set( all_d.columns.to_list() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f622b3-79ed-4e28-bd28-752a0efb223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('analyzed_col len:', len(analyzed_col))\n",
    "print('all_d.columns len', len(all_d.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea4db5c-fcc0-4ba7-87ef-0a9edf9164f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f0a2978-0b5d-4a03-9a6a-a00f1c280d54",
   "metadata": {},
   "source": [
    "### Doing Ordinal and OneHot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4b2ba-004b-4127-a973-9e5370fbf115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding ordinal and onehot columns\n",
    "all_d = ordinal_1hot_encode(all_d.copy(), ord_cat_mapping, cat_to_1Hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eefa6fc-51fb-4797-8295-074b9957dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_d.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f6db8-83ed-41cc-a4e3-5b279e462120",
   "metadata": {},
   "source": [
    "### Working on Number Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e715e0-852c-4ec4-958b-d74985f36db8",
   "metadata": {},
   "source": [
    "> **Skew Col**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58250562-a7c4-4e94-8dbe-c69b80d38a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed = all_d[numbers_col].skew()\n",
    "len(skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd7f992-20f5-44d2-b2a1-6f4e94bd6282",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed = skewed[skewed >= 0.7]\n",
    "skewed = skewed.index\n",
    "len(skewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44559b67-d554-4041-b2a3-176199e9a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_data_skew = Pipeline([('scaler', RobustScaler()), \n",
    "                          ('yeo', PowerTransformer(method='yeo-johnson'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b76a3-e717-47ae-9f46-9b4bc13407c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the skew data\n",
    "# all_d2 = all_d.copy()\n",
    "all_d[skewed] = fix_data_skew.fit_transform(all_d[skewed].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a1f6b-c883-4c79-b996-e8b35373a9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb9529-6c87-4c56-a21c-aa7892187603",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427948b2-3178-49dc-b207-da2386c596f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_skew(all_d.copy(), numbers_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6601b1-915c-4394-966d-17a4462b2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_skew_cols(df, cols, treshold=0.7):\n",
    "    \n",
    "    skewed = all_d[cols].skew()\n",
    "    \n",
    "    skewed = skewed[skewed >= 0.7]\n",
    "    skewed = skewed.index\n",
    "    \n",
    "    print('{} features with skewe >= { }'.format( len(skewed), treshold ) )\n",
    "    \n",
    "    fix_data_skew = Pipeline([('scaler', RobustScaler()), \n",
    "                          ('yeo', PowerTransformer(method='yeo-johnson'))])\n",
    "    \n",
    "    df[skewed] = fix_data_skew.fit_transform(df[skewed].copy())\n",
    "    \n",
    "    return df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e36385-2043-4eb7-9186-a88801ad7762",
   "metadata": {},
   "source": [
    "> **Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f5d342-f107-449a-b20f-4faabb95a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tr = all_d[ all_d['Training']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfde5e36-121f-4d33-9345-b40f3ad4c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop, mutual_info_df = feature_selection(d_tr.drop(columns='SalePrice').copy(), d_tr['SalePrice'].copy(), verbose=True, sorted_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f47078-0e7c-4e10-b8e2-baf9c77810dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7523a5-5a99-45f2-a0cd-1b9b3cc1d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_d.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d506c8ec-be57-4862-b665-a01425b30ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3d54aa-45a8-4e4f-ab9e-fca86c4f8ca7",
   "metadata": {},
   "source": [
    "> **Polynomial and Interaction Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaff974-2a72-4624-b3b5-61a1a31f0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_d.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5cc998-719c-48e2-82ea-be6bf18aa6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_df.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7fb1b-6b6c-491f-a3aa-52d62aa49867",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(numbers_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89879bb4-aa8b-4b9a-8542-4c16f7a3f2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
