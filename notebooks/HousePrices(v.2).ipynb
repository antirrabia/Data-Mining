{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc02876-6c6d-45fb-8704-3b6eaaf01ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from category_encoders import OrdinalEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0f03ff-e61e-4c5f-a494-e09454585ecb",
   "metadata": {
    "tags": []
   },
   "source": [
    "###\n",
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b701d0db-f421-4766-9b56-8727b82008a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tr = pd.read_csv('/Users/antirrabia/Documents/01-GitHub/DataMining-_-/CSV/HousePrices/train.csv', index_col='Id')\n",
    "d_te = pd.read_csv('/Users/antirrabia/Documents/01-GitHub/DataMining-_-/CSV/HousePrices/test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2f14f-ed77-43f9-9fc5-74ea2acc732b",
   "metadata": {
    "tags": []
   },
   "source": [
    "###\n",
    "> **Training** and **test** sets  \n",
    "> Deliting a **zero varianza** columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a62563-4ebb-478e-a6ba-6eb941ac22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = d_tr.SalePrice.copy()\n",
    "\n",
    "# Utilities has just 2 categories, and one of them\n",
    "# just appears once so we delete the whole column.\n",
    "d_tr = d_tr.drop(columns='Utilities')\n",
    "d_te = d_te.drop(columns='Utilities')\n",
    "\n",
    "\n",
    "all_d = pd.concat([d_tr.copy(), d_te.copy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec433a5-29ae-4e20-bc78-a33bbd67b475",
   "metadata": {
    "tags": []
   },
   "source": [
    "####\n",
    "> A set of the **raw columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55a41f-6bca-4825-aeee-103bbe9ad60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_columns = set( all_d.columns )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aebf02-ddb5-4117-9793-322e2efa273c",
   "metadata": {
    "tags": []
   },
   "source": [
    "###\n",
    "## Imputing **nan**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86325da7-80b2-4ee3-9a64-f45e1bb380ae",
   "metadata": {},
   "source": [
    "> columns with **nan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a5562-60cd-41d9-9895-76953a5ea693",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_columns = all_d.columns[all_d.isna().any()].to_list()\n",
    "\n",
    "print('number of columns that has nan: ', len(nan_columns)) #This inclued 'SalesPrice' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af58ab1-507a-4e8b-b5aa-39ed8db19d90",
   "metadata": {},
   "source": [
    "> **coustum** Functions and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ecc14c-145d-4928-9ecb-d2f4ef4a2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34 columns with nan\n",
    "\n",
    "def fillWithNone(df):\n",
    "    ''' nan in 'PoolQC' means 'no pool' \n",
    "        nan in 'MiscFeature' means 'no misc feature'\n",
    "        nan in 'Alley' means 'no alley acces'\n",
    "        nan in 'Fence' means 'no fence'\n",
    "        nan in 'FireplaceQu' means 'no Fireplace'\n",
    "        nan in 'GarageType', 'GarageFinish', 'GarageQual',\n",
    "            'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1'\n",
    "            'BsmtFinType1', 'MasVnrType', 'MSSubClass'\n",
    "            'GarageCond' replaced with 'None' too\n",
    "    \n",
    "        recive a df\n",
    "    '''\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    columns = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', \n",
    "               'FireplaceQu', 'GarageType', 'GarageFinish', \n",
    "               'GarageQual', 'GarageCond', 'BsmtQual',\n",
    "               'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
    "               'BsmtFinType2', 'MasVnrType'\n",
    "              ]\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna('None')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fillWithZero(df):\n",
    "    ''' nan \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    columns = ['GarageYrBlt', 'GarageArea', 'GarageCars',\n",
    "               'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "               'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath',\n",
    "               'MasVnrArea'\n",
    "              ]\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fillWithMode(df):\n",
    "    ''' fill missing values with mode, median\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    \n",
    "    columns = ['Electrical', 'KitchenQual', 'Exterior1st',\n",
    "               'Exterior2nd', 'SaleType'\n",
    "              ]\n",
    "    \n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    # filling with median of each 'Neighborhood'\n",
    "    df['LotFrontage'] = (\n",
    "                     df.groupby('Neighborhood')['LotFrontage']\n",
    "                     .transform(lambda x: x.fillna(x.median()))\n",
    "                    )  \n",
    "    \n",
    "    # nan means Typical\n",
    "    df['Functional'] = df['Functional'].fillna('Typ')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def mszoning(df):\n",
    "    ''' recives a DF this imputation takes place on test data only'''\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    idotrr = ( (df['Neighborhood'] == 'IDOTRR') & (df['MSZoning'].isna()) )\n",
    "    mitchel = ( (df['Neighborhood'] == 'Mitchel') & (df['MSZoning'].isna()) )\n",
    "    \n",
    "    df.loc[ idotrr , 'MSZoning'] = 'RM'\n",
    "    df.loc[ mitchel, 'MSZoning'] = 'RL'\n",
    "    \n",
    "#     # to test this function out of here\n",
    "#     temp = mszoning(d_te)\n",
    "#     # lable index acces at [1916, 2217, 2251, 2905\n",
    "#     temp.loc[[1916, 2217, 2251, 2905], 'MSZoning']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "none_func = FunctionTransformer(fillWithNone, validate=False) \n",
    "zero_func = FunctionTransformer(fillWithZero, validate=False) \n",
    "mode_func = FunctionTransformer(fillWithMode, validate=False)\n",
    "mszo_func = FunctionTransformer(mszoning, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3b40d-5801-45fb-957c-35678a3329fd",
   "metadata": {},
   "source": [
    "> getting the **imputer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1296193c-1efa-4656-9fb4-a4d047bfb196",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Pipeline([\n",
    "                    ('withNone', none_func), \n",
    "                    ('withZero', zero_func), \n",
    "                    ('withMode', mode_func), \n",
    "                    ('mszoni', mszo_func)\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2718e3c-0e57-4f55-97d9-35af407b8dce",
   "metadata": {},
   "source": [
    "###\n",
    "> Imputing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fda0cf6-1590-49f9-96ec-86df03c319de",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d = imputer.fit_transform(all_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a9182c-c8d0-45cf-821a-32c12e998c55",
   "metadata": {},
   "source": [
    "###\n",
    "> checking if there is any columns with **nan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aeecd7-076a-49c5-a28f-2d939d25b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d.columns[new_d.isna().any()].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628201f-0d7a-4c79-8a6e-e7417cb42da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d.SalePrice.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c8b59d-df54-46a9-9acd-95781e5e29d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "###\n",
    "### Reducing low frequency categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "673247ea-dbb0-4428-a6dc-653a729ef4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low frequency categories to 'Other'\n",
    "\n",
    "def lower_than(df, col, percentage):\n",
    "    ''' function that will merge low frequency classes into \n",
    "        a single class 'Others'\n",
    "        \n",
    "        parameters:\n",
    "            df: a DataFrame\n",
    "            col: column's name to work on\n",
    "            percentage: the threshold \n",
    "            \n",
    "        returns:\n",
    "            df: the data frame with col's classes that are lowers\n",
    "                than 'threshold' been repleced with 'Other' category\n",
    "    '''\n",
    "    \n",
    "    # calculating the column frequency\n",
    "    col_freq = df[col].value_counts(normalize=True)\n",
    "    # the getting the column threshold \n",
    "    threshold = col_freq.quantile(q= percentage)\n",
    "    # knowing the classes that are below the threshold\n",
    "    less_freq_classes = col_freq[ col_freq <= threshold ]\n",
    "    \n",
    "    others = less_freq_classes.index.to_list()\n",
    "    \n",
    "    print(others)\n",
    "    \n",
    "    df[col] = df[col].replace(others, 'Others')\n",
    "    \n",
    "    return df\n",
    "\n",
    "con1_others = ['RRAn', 'PosN', 'RRAe', 'PosA', 'RRNn', 'RRNe']\n",
    "roofS_others = ['Gambrel', 'Flat', 'Mansard', 'Shed']\n",
    "foun_others = ['Slab', 'Stone', 'Wood']\n",
    "gara_others = ['None', 'Basment', '2Types', 'CarPort']\n",
    "saleT_others = ['ConLD', 'CWD', 'ConLI', 'ConLw', 'Oth', 'Con']\n",
    "saleC_others = ['Family', 'Alloca', 'AdjLand']\n",
    "exte1_others = ['BrkComm', 'AsphShn', 'Stone', 'CBlock', 'ImStucc']\n",
    "exte2_others = ['BrkComm', 'AsphShn', 'Stone', 'CBlock', 'ImStucc', 'Other']\n",
    "lotC_others = ['FR2', 'FR3']\n",
    "\n",
    "new_d['Condition1'] = new_d['Condition1'].map(lambda x: 'Others' if x in con1_others else x)\n",
    "new_d['RoofStyle'] = new_d['RoofStyle'].map(lambda x: 'Others' if x in roofS_others else x)\n",
    "new_d['Foundation'] = new_d['Foundation'].map(lambda x: 'Others' if x in foun_others else x)\n",
    "new_d['GarageType'] = new_d['GarageType'].map(lambda x: 'Others' if x in gara_others else x)\n",
    "new_d['SaleType'] = new_d['SaleType'].map(lambda x: 'Others' if x in saleT_others else x)\n",
    "new_d['SaleCondition'] = new_d['SaleCondition'].map(lambda x: 'Others' if x in saleC_others else x)\n",
    "new_d['Exterior1st'] = new_d['Exterior1st'].map(lambda x: 'Others' if x in exte1_others else x)\n",
    "new_d['Exterior2nd'] = new_d['Exterior2nd'].map(lambda x: 'Others' if x in exte2_others else x)\n",
    "new_d['LotConfig'] = new_d['LotConfig'].map(lambda x: 'Others' if x in lotC_others else x)\n",
    "\n",
    "\n",
    "# Reducing to a BINARY CLASSES(just 2 clases)\n",
    "\n",
    "# temp = new_d.copy()\n",
    "\n",
    "landC_others = ['HLS', 'Bnk', 'Low']\n",
    "cond2_others = ['Feedr', 'Artery', 'PosN', 'PosA', 'RRNn', 'RRAn', 'RRAe']\n",
    "roofM_others = ['Tar&Grv', 'WdShake', 'WdShngl', 'Metal', 'Membran', 'Roll', 'ClyTile']\n",
    "heati_others = ['GasW', 'Grav', 'Wall', 'OthW', 'Floor']\n",
    "elect_others = ['FuseA', 'FuseF', 'FuseP', 'Mix']\n",
    "\n",
    "\n",
    "new_d['LandContour'] = new_d['LandContour'].map(lambda x: 'Others' if x in landC_others else x)\n",
    "new_d['Condition2'] = new_d['Condition2'].map(lambda x: 'Others' if x in cond2_others else x)\n",
    "new_d['RoofMatl'] = new_d['RoofMatl'].map(lambda x: 'Others' if x in roofM_others else x)\n",
    "new_d['Heating'] = new_d['Heating'].map(lambda x: 'Others' if x in heati_others else x)\n",
    "new_d['Electrical'] = new_d['Electrical'].map(lambda x: 'Others' if x in elect_others else x)\n",
    "\n",
    "# to encode using OneHot (17 so far)\n",
    "cat_to_1Hot = {'Condition1': str, 'RoofStyle': str, 'Foundation': str, 'GarageType': str, 'SaleType': str, \n",
    "               'SaleCondition': str, 'Exterior1st': str, 'Exterior2nd': str, 'LotConfig': str, 'LandContour': str, \n",
    "               'Condition2': str, 'RoofMatl': str, 'Heating': str, 'Electrical': str }\n",
    "\n",
    "# updating data types\n",
    "new_d = new_d.astype(cat_to_1Hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44912ad7-ac9a-47df-b92b-0b91a8aac418",
   "metadata": {},
   "source": [
    "###\n",
    "> changing the **data types** to the columns that  we just reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea78987-7463-44e2-a741-21e2800ba8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d[ list( cat_to_1Hot.keys() ) ].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe87a0-706c-471a-bdb8-e1e231b82f0f",
   "metadata": {},
   "source": [
    "###\n",
    "> Reducing number of classes in **'Neighborhood'** and **'MSSubClass'**   Using **Clusters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b5dd9-db0d-4934-86bb-0c9207b4e43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neig_clusters = KMeans(n_clusters=5, random_state=777)\n",
    "mssu_clusters = KMeans(n_clusters=4, random_state=777)\n",
    "\n",
    "# 'Neighborhood' and 'MSSubClass' stats\n",
    "neig_stats = d_tr.groupby('Neighborhood')['SalePrice'].describe()\n",
    "mssu_stats = d_tr.groupby('MSSubClass')['SalePrice'].describe()\n",
    "\n",
    "# Getting clusters\n",
    "neig_clusters.fit(neig_stats)\n",
    "mssu_clusters.fit(mssu_stats)\n",
    "\n",
    "# preparing DF with cluster lables to merge\n",
    "neig_df = pd.DataFrame({'Neighborhood': neig_stats.index.to_list(),\n",
    "                        'Neighborhood_Cluster': neig_clusters.labels_.tolist()})\n",
    "\n",
    "mssu_df = pd.DataFrame({'MSSubClass': mssu_stats.index.to_list(),\n",
    "                        'MSSubClass_Cluster': mssu_clusters.labels_.tolist() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c101caf6-2c8b-4aa3-9eb4-489fb49329fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clusters(df, col, y, n_cluster, merge=False):\n",
    "    '''\n",
    "        function to boil down a colum to n_cluster\n",
    "        \n",
    "        recive:\n",
    "        \n",
    "            df: a data frame \n",
    "            col: col to make cluster\n",
    "            y: the response variable\n",
    "            n_cluster: stamitation of number of cluster\n",
    "            \n",
    "        return:  \n",
    "            a data frame with 'col' droped, and 'col' + '_cluster' column\n",
    "            is added to the data frame\n",
    "\n",
    "        \n",
    "    '''\n",
    "    col_clusters = KMeans(n_clusters=5, random_state=777)\n",
    "\n",
    "    # 'Neighborhood' and 'MSSubClass' stats\n",
    "    col_stats = df.groupby(col)[y].describe()\n",
    "\n",
    "    # Getting clusters\n",
    "    col_clusters.fit(col_stats)\n",
    "\n",
    "    # preparing DF with cluster lables to merge\n",
    "    new_name = col + '_Cluster'\n",
    "    col_cluster_df = pd.DataFrame( { col: col_stats.index.to_list(),\n",
    "                                     new_name: col_clusters.labels_.tolist()} )\n",
    "    \n",
    "    if merge:\n",
    "        # merging the clusters with the data frame\n",
    "        df = df.merge(col_cluster_df, how='left', on=col)\n",
    "\n",
    "        df[new_name] = df[new_name].astype(str)\n",
    "        \n",
    "        result = df.drop(columns=col)\n",
    "        \n",
    "    else:\n",
    "        result = col_cluster_df\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534881a5-fc63-45f4-b0f2-53664a876b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Neighborhood', 5, 'MSSubClass', 4\n",
    "temp_cluster = make_clusters(d_tr.copy(), 'MSSubClass', 'SalePrice', 4)\n",
    "temp_cluster.drop(columns=col, inplace=)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99faa8e1-a3c6-4a66-9268-f6bdc48240be",
   "metadata": {},
   "source": [
    "###\n",
    "> Features ingenering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5636794e-37e0-424a-88f8-49ca37eda764",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Neighborhood'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m mss_cluster \u001b[38;5;241m=\u001b[39m make_clusters(d_tr\u001b[38;5;241m.\u001b[39mcopy(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSSubClass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalePrice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# merging the clusters with the data frame\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m new_d \u001b[38;5;241m=\u001b[39m \u001b[43mnew_d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnei_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNeighborhood\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m new_d\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeighborhood\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m new_d \u001b[38;5;241m=\u001b[39m new_d\u001b[38;5;241m.\u001b[39mmerge(mss_cluster, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSSubClass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:9345\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9326\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9327\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   9328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9341\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   9342\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9343\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m-> 9345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9354\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9355\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9359\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    696\u001b[0m (\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1110\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(rk)\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1110\u001b[0m     left_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1111\u001b[0m     join_names\u001b[38;5;241m.\u001b[39mappend(lk)\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py:1840\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1838\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Neighborhood'"
     ]
    }
   ],
   "source": [
    "# Creating a new feature 'PeakMonths', 'Unfinished' and 'Splited'\n",
    "peak_moS = [5, 6, 7]\n",
    "unfi_hou = ['1.5Unf', '2.5Unf']\n",
    "spli_hou = ['SFoyer', 'SLvl']\n",
    "\n",
    "new_d['PeakMonths'] = new_d['MoSold'].map(lambda x: 'Peak' if x in peak_moS else 'Normal' )\n",
    "new_d['Finished'] = new_d['HouseStyle'].map(lambda x: 'no' if x in unfi_hou else 'yes') \n",
    "new_d['Splited'] = new_d['HouseStyle'].map(lambda x: 'yes' if x in spli_hou else 'no')\n",
    "\n",
    "new_d['TotalSF'] = new_d['TotalBsmtSF'] + new_d['1stFlrSF'] + new_d['2ndFlrSF']\n",
    "\n",
    "\n",
    "# we will use the training data because if we uses new_d\n",
    "# it has 'nan' in 'SalePrice'. test data does not have 'SalePrice'\n",
    "# 'Neighborhood', 5, 'MSSubClass', 4\n",
    "nei_cluster = make_clusters(d_tr.copy(), 'Neighborhood', 'SalePrice', 5)\n",
    "mss_cluster = make_clusters(d_tr.copy(), 'MSSubClass', 'SalePrice', 4)\n",
    "\n",
    "# merging the clusters with the data frame\n",
    "new_d = new_d.merge(nei_cluster, how='left', on='Neighborhood')\n",
    "new_d.drop(columns='Neighborhood', inplace=True)\n",
    "\n",
    "new_d = new_d.merge(mss_cluster, how='left', on='MSSubClass')\n",
    "new_d.drop(columns='MSSubClass', inplace=True)\n",
    "\n",
    "\n",
    "# updating types\n",
    "new_d = new_d.astype( {'PeakMonths':str, 'Finished':str, 'Splited':str,\n",
    "                       'Neighborhood_Cluster': str, 'MSSubClass_Cluster': str} )\n",
    "\n",
    "# updating cat_to_1Hot\n",
    "cat_to_1Hot.update( {'PeakMonths':str, 'Finished':str, 'Splited':str,\n",
    "                       'Neighborhood_Cluster': str, 'MSSubClass_Cluster': str} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd8ff45-fd0c-413a-b477-303e2565c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d[cat_to_1Hot.keys()].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823aa7d-22fd-49db-b486-8cc43ca7704b",
   "metadata": {},
   "source": [
    "###\n",
    "## Encoding Ordinal Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e612d-3196-44b5-b5d5-e262cdd7f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ****** All writed by me ****** #####\n",
    "##########################################\n",
    "\n",
    "ord_cat_mapping = [\n",
    "    {\n",
    "        'col': 'FireplaceQu',\n",
    "        'mapping': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "    },\n",
    "    {\n",
    "        'col': 'GarageQual',\n",
    "        'mapping': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "    },\n",
    "    {\n",
    "        'col': 'GarageCond',\n",
    "        'mapping': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "    },\n",
    "    {\n",
    "        'col': 'BsmtFinType1',\n",
    "        'mapping': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "    },\n",
    "    {\n",
    "        'col': 'BsmtFinType2',\n",
    "        'mapping': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "    },\n",
    "    {\n",
    "        'col': 'ExterQual',\n",
    "        'mapping': {'Fa': 0, 'TA': 1, 'Gd': 2, 'Ex': 3}\n",
    "    },\n",
    "    {\n",
    "        'col': 'ExterCond',\n",
    "        'mapping': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\n",
    "    },\n",
    "    {\n",
    "        'col': 'BsmtQual',\n",
    "        'mapping': {'None': 0 , 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\n",
    "    },\n",
    "    {\n",
    "        'col': 'BsmtCond',\n",
    "        'mapping': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4}\n",
    "    },\n",
    "    {\n",
    "        'col': 'PoolQC',\n",
    "        'mapping': {'None': 0, 'Fa': 1, 'Gd': 2, 'Ex': 3}\n",
    "    },\n",
    "    {\n",
    "        'col': 'HeatingQC',\n",
    "        'mapping': {'Po': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}\n",
    "    },\n",
    "    {\n",
    "        'col': 'KitchenQual',\n",
    "        'mapping': {'Fa': 0, 'TA': 1, 'Gd': 2, 'Ex': 3}\n",
    "    },\n",
    "    {\n",
    "        'col': 'BsmtExposure',\n",
    "        'mapping': {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}\n",
    "    },\n",
    "    {\n",
    "        'col': 'Functional',\n",
    "        'mapping': {'Sev': 0, 'Maj2': 1, 'Maj1': 2, 'Mod': 3, 'Min2': 4, 'Min1': 5, 'Typ': 6}\n",
    "    },\n",
    "    {\n",
    "        'col': 'GarageFinish',\n",
    "        'mapping': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "    },\n",
    "    {\n",
    "        'col': 'Fence',\n",
    "        'mapping': {'None': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n",
    "    },\n",
    "    {\n",
    "        'col': 'CentralAir',\n",
    "        'mapping': {'N': 0, 'Y': 1}\n",
    "    },\n",
    "    {\n",
    "        'col': 'PavedDrive',\n",
    "        'mapping': {'N': 0, 'P': 1, 'Y': 2}\n",
    "    },\n",
    "    {\n",
    "        'col': 'Street',\n",
    "        'mapping': {'Grvl': 0, 'Pave': 1}\n",
    "    },\n",
    "    {\n",
    "        'col': 'Alley',\n",
    "        'mapping': {'None': 0, 'Grvl': 1, 'Pave': 2}\n",
    "    },\n",
    "    {\n",
    "        'col': 'LandSlope',\n",
    "        'mapping': {'Gtl': 0, 'Mod': 1, 'Sev': 2}\n",
    "    },\n",
    "    {\n",
    "        'col': 'LotShape',\n",
    "        'mapping': {'Reg': 0, 'IR1': 1, 'IR2': 2, 'IR3': 3}\n",
    "    },\n",
    "    {\n",
    "        'col': 'HouseStyle', \n",
    "        'mapping': {'SLvl': 0, 'SFoyer': 0, '1Story': 1, '1.5Fin': 2, \n",
    "                    '1.5Unf': 2, '2Story': 3, '2.5Unf': 4, '2.5Fin': 4}\n",
    "    }\n",
    "]\n",
    "\n",
    "# to encode\n",
    "# hou_sty = {'SLvl': 0, 'SFoyer': 0, '1Story': 1, '1.5Fin': 2, '1.5Unf': 2, '2Story': 3, '2.5Unf': 4, '2.5Fin': 4}\n",
    "# new_d['HouseStyle'] = new_d['HouseStyle'].map(hou_sty)\n",
    "\n",
    "\n",
    "# list of categorical columns(23) that are alredy done\n",
    "ord_cat_DONE = {'FireplaceQu': str, 'GarageQual': str,'GarageCond': str,'BsmtFinType1': str,\n",
    "                 'BsmtFinType2': str,'ExterQual': str,'ExterCond': str,'BsmtQual': str,\n",
    "                 'BsmtCond': str,'PoolQC': str,'HeatingQC': str,'KitchenQual': str,\n",
    "                 'BsmtExposure': str,'Functional': str,'GarageFinish': str,'Fence': str, \n",
    "                 'CentralAir': str, 'PavedDrive': str,'Street': str,'Alley': str,\n",
    "                 'LandSlope': str,'LotShape': str, 'HouseStyle': str}\n",
    "\n",
    "\n",
    "# no work on the next columns\n",
    "cat_DONE = ['OverallQual', 'OverallCond', 'MSSubClass']\n",
    "\n",
    "# object columns (need to be encode)\n",
    "cat_NoDone = ['Neighborhood', 'MSZoning', 'LotConfig', 'Condition1', 'BldgType', 'RoofStyle', \n",
    "              'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'GarageType', 'MiscFeature',\n",
    "              'MoSold', 'YrSold', 'SaleType', 'SaleCondition']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4b111-aeb5-4b96-913f-67c22d79ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OrdinalEncoder\n",
    "oe = OrdinalEncoder(mapping=ord_cat_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161018a8-f117-47d1-a45c-0d8ff490aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical columns\n",
    "new_d = oe.fit_transform(new_d)\n",
    "\n",
    "# updating the types\n",
    "new_d = new_d.astype(ord_cat_DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4a284-99db-4a8c-b567-45ee0f8f875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d[ord_cat_DONE.keys()].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e7ef7-6a3b-4044-83d9-179a244e1bef",
   "metadata": {},
   "source": [
    "# Testing the ordinal encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4efc7-a72c-4a93-a9a8-85098056e0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
